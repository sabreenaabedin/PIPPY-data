corrAttr <- cor(dd1[,c('attr_o','attr','sinc','intel','fun','amb','met','dec')])
corrAttr <- cor(dd1[,c('attr_o','attr','sinc','intel','fun','amb','met','race_o','age_o')])
corrplot(corrAttr, order = 'hclust')
dd1_test[12]
names(dd1_test)
p1Rat <- predict(adaboostRat,dd1_test[-84])
RC1Rat <- roc(dd1_test$dec,p1Rat$prob[,2])
plot(RC1Rat, legacy.axes=TRUE)
auc(RC1Rat)
library(pROC)
p1Rat <- predict(adaboostRat,dd1_test[-84])
RC1Rat <- roc(dd1_test$dec,p1Rat$prob[,2])
plot(RC1Rat, legacy.axes=TRUE)
auc(RC1Rat)
adaboostRatM <- boosting(dec~age_o+race_o+attr+sinc+intel+fun+amb+met,data = dd1_trainM, boos=FALSE, mfinal=20, coeflearn='Freund')
adaboostRatM$importance[which(adaboostRatM$importance>0)]
p1RatM <- predict(adaboostRat,dd1_testM[-84])
RC1RatM <- roc(dd1_testM$dec,p1RatM$prob[,2])
plot(RC1RatM, legacy.axes=TRUE)
auc(RC1RatM)
dd1_testM <- dd1_test %>% filter(gender == 1)
dd1_testF <- dd1_test %>% filter(gender == 0)
p1RatM <- predict(adaboostRat,dd1_testM[-84])
RC1RatM <- roc(dd1_testM$dec,p1RatM$prob[,2])
plot(RC1RatM, legacy.axes=TRUE)
auc(RC1RatM)
p1RatF <- predict(adaboostRat,dd1_testF[-84])
RC1RatF <- roc(dd1_testF$dec,p1RatF$prob[,2])
plot(RC1RatF, legacy.axes=TRUE)
auc(RC1RatF)
plot(RC1Rat, legacy.axes = TRUE)
lines(RC1RatM)
lines(RC1RatM, col = 'Blue')
lines(RC1RatF, col = 'Orange')
plot(RC1Rat, legacy.axes = TRUE, col = 'Green')
lines(RC1RatM, col = 'Blue')
lines(RC1RatF, col = 'Orange')
corrAttr <- cor(dd1[,c('attr_o','attr','sinc','intel','fun','amb','met','race','age')])
corrplot(corrAttr, order = 'hclust')
adaboostRat$importance[which(adaboostRat$importance>0)]
##Males and Females
adaboostRat <- boosting(dec~age+race_o+attr+sinc+intel+fun+amb+met,data = dd1_train, boos=FALSE, mfinal=20, coeflearn='Freund')
##Males and Females
adaboostRat <- boosting(dec~age+race+attr+sinc+intel+fun+amb+met,data = dd1_train, boos=FALSE, mfinal=20, coeflearn='Freund')
adaboostRat$importance[which(adaboostRat$importance>0)]
##Just males
adaboostRatM <- boosting(dec~age+race+attr+sinc+intel+fun+amb+met,data = dd1_trainM, boos=FALSE, mfinal=20, coeflearn='Freund')
##Males and Females
adaboostRat <- boosting(dec~age_o+race_o+attr+sinc+intel+fun+amb+met,data = dd1_train, boos=FALSE, mfinal=20, coeflearn='Freund')
adaboostRat$importance[which(adaboostRat$importance>0)]
adaboostRatM$importance[which(adaboostRatM$importance>0)]
##Just males
adaboostRatM <- boosting(dec~age_o+race_o+attr+sinc+intel+fun+amb+met,data = dd1_trainM, boos=FALSE, mfinal=20, coeflearn='Freund')
adaboostRatF$importance[which(adaboostRatF$importance>0)]
install.packages('feedeR')
library(feedeR)
feed.extract('https://www.amazon.com/gp/rss/bestsellers/beauty/ref=zg_bs_beauty_rsslink')
am_beauty <- feed.extract('https://www.amazon.com/gp/rss/bestsellers/beauty/ref=zg_bs_beauty_rsslink')
am_beaty$items
am_beauty$items
am_beauty$items$title
library(feedeR)
am_beauty <- feed.extract('https://www.amazon.com/gp/rss/bestsellers/beauty/11060451/ref=zg_bs_11060451_rsslink')
am_beauty$items$title
am_beauty$items
am_beauty$items$rank <- substring(am_beauty$items$title, 2,3)
am_beauty$items$rank <- gsub(":","",am_beauty$items$rank)
am_beauty$items$rank <- as.integer(am_beauty$items$rank)
am_beauty$items$title
for (i in 1:10){
am_beauty$items$name[i] <- substring(am_beauty$items$title[i], 5, nchar(am_beauty$items$title[i]))
}
am_beauty$items$name
ranks <- data.frame(am_beauty$items$name, am_beauty$items$rank, am_beauty$items$date)
ranks
colnames(ranks) = c('Name','Rank', 'Date')
ranks
write.csv(ranks, file = 'Ranks3.csv')
for (i in 1:10){
am_beauty$items$name[i] <- substring(am_beauty$items$title[i], 5, nchar(am_beauty$items$title[i]))
}
words <- strsplit(ranks$Name, ' ')
ranks
typeof(ranks$Name)
ranks$Name
ambeauty$item$name[i]
am_beauty$items$name[1]
typeof(am_beauty$items$name)
words <- strsplit(am_beauty$items$name[1], ' ')
words
x <- c(as = "asfef", qu = "qwerty", "yuiop[", "b", "stuff.blah.yech")
strsplit(x, "e")
y<-strsplit(x, "e")
words[2]
words[,3]
words[1]
words[[2]]
am_beauty$items$title$getText()
getText(am_beauty$items$title)
library(base64enc)
library(ROAuth)
require(RCurl)
library(stringr)
library(ggmap)
library(dplyr)
library(plyr)
library(tm)
library(wordcloud)
getText(am_beauty$items$title)
am_beauty$items$title$getText()
?twitteR$getText()
?getText
??getText
??twitteR::getText
library(twitteR)
# get the text
some_txt = sapply(some_tweets, function(x) x$getText())
# get the text
some_txt = sapply(am_beauty$items$name, function(x) x$getText())
am_beauty$items$name
typeof(am_beauty$items$name)
words <- strsplit(am_beauty$items$name, ' ')
str(words)
setwd('C:/Users/Student/Documents/Capstone')
write.csv(ranks, file = 'Ranks3.csv')
ranks1 <- read.csv("Ranks3.csv")
ranks1 <- read.csv("Ranks1.csv")
ranks1 <- read.csv("Ranks.csv")
ranks2<- read.csv('Ranks2.csv')
ranks3 <- read.csv('Ranks3.csv')
ranks <- rbind(ranks1, ranks2, ranks3)
write.csv(rankTot, 'OverallRankingsOverTime.csv')
rankTot <- rbind(ranks1, ranks2, ranks3)
write.csv(rankTot, 'OverallRankingsOverTime.csv')
ranks <- data.frame(am_beauty$items$name, am_beauty$items$rank, am_beauty$items$date)
colnames(ranks) = c('Name','Rank', 'Date')
rankTot$words <- as.character(rankTot$Name)
rankTot$words
rank_words <- rankTot %>% tidytext::unnest_tokens(word, words) %>% mutate(Date, Rank)
typeof(rank_words$Date)
rank_words$Date <- as.Date(rank_words$Date)
rankTot$Date
max(rank_words$Date)
rank_w <- rank_words %>% inner_join(by = c(word='word'))
?inner_join
count(rank_words, word)
count(rank_words, 'word')
list1 <- rep(1,length(rank_words))
list1 <- rep(1,numrow(rank_words))
list1 <- rep(1,nrow(rank_words))
rank_words <- cbind(rank_words, list1)
aggregate(rank_words$list1, by = list(Category = rank_words$word), fun = SUM)
aggregate(rank_words$list1, by = list(Category = rank_words$word), FUN=sum)
rank_words <- rankTot %>% tidytext::unnest_tokens(word, words) %>% mutate(Date, Rank)
rank_words$Date <- as.Date(rank_words$Date)
word_counts <- count(rank_words, 'word')
rank_words <- merge(rank_words, word_counts[,c('word','freq')],by='word')
word_counts <- merge(word_counts, rank_words[,c('word','Date')],by='word')
min(rank_words$Date %>% filter(word == 'viva'))
min(rank_words %>% filter(word == 'viva') %>% select(Date))
min(rank_words$Date)
(rank_words %>% filter(word == 'viva') %>% select(Date))
typeof(rank_words %>% filter(word == 'viva') %>% select(Date))
(rank_words %>% filter(word == 'viva') %>% select(Date))$Date
min(rank_words %>% filter(word == 'viva') %>% select(Date))$Date)
min((rank_words %>% filter(word == 'viva') %>% select(Date))$Date)
word_counts$minDate <- rep(,nrow(word_counts))
word_counts$minDate <- rep("",nrow(word_counts))
word_counts$minDate[i] <- ((rank_words %>% filter(word == w) %>% select(Date))$Date)
for (i in nrow(word_counts)){
w = word_counts$word[i]
word_counts$minDate[i] <- ((rank_words %>% filter(word == w) %>% select(Date))$Date)
}
word_counts$minDate[i] <- min((rank_words %>% filter(word == w) %>% select(Date))$Date)
for (i in nrow(word_counts)){
w = word_counts$word[i]
word_counts$minDate[i] <- min((rank_words %>% filter(word == w) %>% select(Date))$Date)
}
word_counts$minDate[i]
word_counts$minDate[i] <- as.Date(min((rank_words %>% filter(word == w) %>% select(Date))$Date))
for (i in nrow(word_counts)){
w = word_counts$word[i]
word_counts$minDate[i] <- as.Date(min((rank_words %>% filter(word == w) %>% select(Date))$Date))
word_counts$minDate[i]
}
for (i in nrow(word_counts)){
w = word_counts$word[i]
word_counts$minDate[i] <- as.Date(min((rank_words %>% filter(word == w) %>% select(Date))$Date))
print(word_counts$minDate[i])
}
for (i in nrow(word_counts)){
i
w = word_counts$word[i]
word_counts$minDate[i] <- as.Date(min((rank_words %>% filter(word == w) %>% select(Date))$Date))
}
nrow(word_counts)
for (i in 1:nrow(word_counts))){
w = word_counts$word[i]
word_counts$minDate[i] <- as.Date(min((rank_words %>% filter(word == w) %>% select(Date))$Date))
}
for (i in 1:nrow(word_counts)){
w = word_counts$word[i]
word_counts$minDate[i] <- as.Date(min((rank_words %>% filter(word == w) %>% select(Date))$Date))
}
as.Date(min((rank_words %>% filter(word == w) %>% select(Date))$Date))
word_counts$minDate <- rep(as.Date("2018-02-13"),nrow(word_counts))
for (i in 1:nrow(word_counts)){
w = word_counts$word[i]
word_counts$minDate[i] <- as.Date(min((rank_words %>% filter(word == w) %>% select(Date))$Date))
}
table(word_counts$minDate)
rank_words <- merge(rank_words, word_counts[,c('word','freq','minDate')],by='word')
word_counts <- merge(word_counts, rank_words[,c('word','Date','Rank')],by='word')
word_counts$minDate <- rep(as.Date("2018-02-13"),nrow(word_counts))
for (i in 1:nrow(word_counts)){
w = word_counts$word[i]
word_counts$minDate[i] <- as.Date(min((rank_words %>% filter(word == w) %>% select(Date))$Date))
}
word_counts <- merge(word_counts, rank_words[,c('word','Date')],by='word')
word_counts <- count(rank_words, 'word')
word_counts <- merge(word_counts, rank_words[,c('word','Date')],by='word')
word_counts$minDate <- rep(as.Date("2018-02-13"),nrow(word_counts))
for (i in 1:nrow(word_counts)){
w = word_counts$word[i]
word_counts$minDate[i] <- as.Date(min((rank_words %>% filter(word == w) %>% select(Date))$Date))
}
rank_words <- rankTot %>% tidytext::unnest_tokens(word, words) %>% mutate(Date, Rank)
rank_words$Date <- as.Date(rank_words$Date)
max(rank_words$Date)
word_counts <- count(rank_words, 'word')
word_counts <- merge(word_counts, rank_words[,c('word','Date')],by='word')
word_counts$minDate <- rep(as.Date("2018-02-13"),nrow(word_counts))
for (i in 1:nrow(word_counts)){
w = word_counts$word[i]
word_counts$minDate[i] <- as.Date(min((rank_words %>% filter(word == w) %>% select(Date))$Date))
}
write.csv(word_counts, 'WordCountRanksAmazon.csv')
rank_words <- merge(rank_words, word_counts[,c('word','freq','minDate')],by='word')
rank_words <- rankTot %>% tidytext::unnest_tokens(word, words) %>% mutate(Date, Rank)
rank_words$Date <- as.Date(rank_words$Date)
rank_words <- merge(rank_words, word_counts[,c('word','minDate')],by='word')
rank_words <- rankTot %>% tidytext::unnest_tokens(word, words) %>% mutate(Date, Rank)
rank_words$Date <- as.Date(rank_words$Date)
rank_words <- merge(rank_words, word_counts[,c('word','freq')],by='word')
rank_words <- merge(rank_words, word_counts[,c('word')],by='word')
rank_words <- rankTot %>% tidytext::unnest_tokens(word, words) %>% mutate(Date, Rank)
rank_words$Date <- as.Date(rank_words$Date)
rank_words <- merge(rank_words, word_counts[,c('word')],by='word')
rank_words <- merge(rank_words,word_counts[,c('word','freq')],by='word')
rank_words <-rankTot %>% tidytext::unnest_tokens(word, words) %>% mutate(Date, Rank)
rank_words$Date <- as.Date(rank_words$Date)
word_counts <- count(rank_words, 'word')
rank_words <- merge(rank_words,word_counts[,c('word','freq')],by='word')
write.csv(rank_words, 'rank_wordsAmazon.csv')
max(word_counts$freq)
rankTot$words <- as.character(rankTot$Name)
rankTot$words = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", rankTot$words)
# remove at people
rankTot$words = gsub("@\\w+", "", rankTot$words)
# remove punctuation
rankTot$words = gsub("[[:punct:]]", "", rankTot$words)
# remove numbers
rankTot$words = gsub("[[:digit:]]", "", rankTot$words)
# remove html links
rankTot$words = gsub("http\\w+", "", rankTot$words)
# remove unnecessary spaces
rankTot$words = gsub("[ \t]{2,}", "", rankTot$words)
rankTot$words = gsub("^\\s+|\\s+$", "", rankTot$words)
rankTot$words = gsub('???','',rankTot$words)
rankTot$words = gsub('etc','',rankTot$words)
rank_words <-rankTot %>% tidytext::unnest_tokens(word, words) %>% mutate(Date, Rank)
rank_words$Date <- as.Date(rank_words$Date)
max(rank_words$Date)
word_counts <- count(rank_words, 'word')
rank_words <- merge(rank_words,word_counts[,c('word','freq')],by='word')
write.csv(rank_words, 'rank_wordsAmazon.csv')
word_counts <- merge(word_counts, rank_words[,c('word','Date')],by='word')
word_counts$minDate <- rep(as.Date("2018-02-13"),nrow(word_counts))
for (i in 1:nrow(word_counts)){
w = word_counts$word[i]
word_counts$minDate[i] <- as.Date(min((rank_words %>% filter(word == w) %>% select(Date))$Date))
}
write.csv(word_counts, 'WordCountRanksAmazon.csv')
save.image("~/Capstone/AmazonRankData.RData")
load("~/Capstone/AmazonRankData.RData")
rank_words
rank_words %>% group_by(word) %>% summary()
library(feedeR)
library(base64enc)
library(ROAuth)
require(RCurl)
library(stringr)
library(ggmap)
library(dplyr)
library(plyr)
library(tm)
library(wordcloud)
rank_words %>% group_by(word) %>% summary()
rank_words %>% group_by(word) %>% summarize(rank)
rank_words %>% group_by(word) %>% summarize(mean(rank))
rank_words %>% group_by(word) %>% (avg = mean(rank))
rank_words %>% group_by(word) %>% summarize(avg = mean(rank))
rank_words %>% group_by(word) %>% summarize(avg = mean(as.Integer(rank)))
rank_words %>% group_by(word) %>% summarize(avg = mean(as.integer(rank)))
typeof(rank_words$Rank)
rank_words %>% group_by(word) %>% summarize(avg = mean((Rank)))
rank_words$word
rank_words %>% group_by(word)# %>% summarize(avg = mean((Rank)))
rank_words %>% group_by(word) %>% summarize(avg = mean((Rank)))
rank_words %>% group_by(word) %>% summarize(mean((Rank)))
rank_words %>% dplyr::group_by(word) %>% dplyr::summarize(mean((Rank)))
AveWordRank <- rank_words %>% dplyr::group_by(word) %>% dplyr::summarize(mean((Rank)))
AveWordRank <- rank_words %>% dplyr::group_by(word) %>% dplyr::mutate((freq))
AveWordRank
AveWordRank <- rank_words %>% dplyr::group_by(word) %>% dplyr::summarize(mean((Rank)))
AveWordRank
AveWordRank <- rank_words %>% dplyr::group_by(word) %>% dplyr::summarize(mean((Rank))) %>% dplyr::mutate((freq))
AveWordRank <- rank_words %>% dplyr::group_by(word) %>% dplyr::summarize(mean((Rank))) %>% dplyr::mutate((rank_words$freq))
AveWordRank <- rank_words %>% dplyr::group_by(word) %>% dplyr::summarize(mean((Rank)))
?transmute
AveWordRank$freq <- rank_words %>% dplyr::group_by(word) %>% dplyr::mutate((rank_words$freq))
AveWordRank$freq <- rank_words %>% dplyr::group_by(word) %>% dplyr::mutate((freq))
AveWordRank <- merge(AveWordRank,word_counts[,c('word','freq')],by='word')
AveWordRank
AveWordRank <- AveWordRank[!duplicated(AveWordRank),]
AveWordRank
write.csv(AveWordRank, 'aveWordRank.csv')
load("~/Capstone/blogs.RData")
reddit <- read.table('redditData.txt')
setwd('~/GitHub/PIPPY-data')
reddit <- read.table('redditData.txt')
reddit <- read.delim('redditData.txt')
head(reddit)
View(reddit)
library(tidyverse)
library(base64enc)
library(ROAuth)
require(RCurl)
library(stringr)
library(ggmap)
library(dplyr)
library(plyr)
library(tm)
library(wordcloud)
library(SnowballC)
library(genderizeR)
library(gender)
library(tidytext)
library(topicmodels)
library(reshape2)
library(lubridate)
library(tidyverse)
library(base64enc)
library(ROAuth)
require(RCurl)
library(stringr)
library(ggmap)
library(dplyr)
library(plyr)
library(tm)
library(wordcloud)
library(SnowballC)
library(genderizeR)
library(gender)
library(tidytext)
library(topicmodels)
library(reshape2)
library(lubridate)
setwd('~/Gitdir/PIPPY-data/Data/Blogs')
blogs <- data.frame()
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)) {assign('blog_name', read.csv(temp[i], na.strings = ""))
if(!is.null(blog_name$Date)){
blog_name <- blog_name[c('Date','Text')]
blogs<- rbind(blogs,blog_name)}
}
View(blogs)
View(blog_name)
# Remove all NAs
blogs <- blogs[rowSums(is.na(blogs)) == 0,]
View(blogs)
View(blogs)
str(blogs)
# Change text to character
blogs$Text <- as.character(blogs$Text)
str(blogs)
View(blogs)
# Change date to dates
blogs$Date <- as.Date(blogs$Date)
# Change date to dates
blogs$Date <- as.character(blogs$Date)
blogs$Date <- as.Date(blogs$Date)
str(blogs)
blogs$Date <- gsub("[[:punct:]]", "", blogs$Date)
View(blogs)
View(blogs)
#### Load in data ####
setwd('~/Gitdir/PIPPY-data/Data/Blogs')
blogs <- data.frame()
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)) {assign('blog_name', read.csv(temp[i], na.strings = ""))
if(!is.null(blog_name$Date)){
blog_name <- blog_name[c('Date','Text')]
blogs<- rbind(blogs,blog_name)}
}
#### Clean the data ####
# Remove all NAs
blogs <- blogs[rowSums(is.na(blogs)) == 0,]
# Change text to character
blogs$Text <- as.character(blogs$Text)
blogs$Date <- as.character(blogs$Date)
blogs$Date <- gsub("['", "", blogs$Date)
blogs$Date <- gsub("']","", blogs$Date)
View(blogs)
blogs$Date <- gsub(" ['", "", blogs$Date)
View(blog_name)
View(blog_name)
View(blogs)
View(blogs)
blogs$Date <- gsub("['", "", blogs$Date)
blogs$Date <- gsub("']","", blogs$Date)
View(blogs)
blogs$Date <- gsub("[", "", blogs$Date)
blogs$Date <- gsub("[]", "", blogs$Date)
View(blogs)
blogs$Date <- gsub("\\['|\\']", "", blogs$Date)
View(blogs)
#### Load in data ####
setwd('~/Gitdir/PIPPY-data/Data/Blogs')
blogs <- data.frame()
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)) {assign('blog_name', read.csv(temp[i], na.strings = ""))
if(!is.null(blog_name$Date)){
blog_name <- blog_name[c('Date','Text')]
blogs<- rbind(blogs,blog_name)}
}
#### Clean the data ####
# Remove all NAs
blogs <- blogs[rowSums(is.na(blogs)) == 0,]
# Change text to character
blogs$Text <- as.character(blogs$Text)
# Change date to dates
blogs$Date <- as.character(blogs$Date)
View(blogs)
blogs$Date <- gsub("\\['|\\']", "", blogs$Date)
View(blogs)
View(blogs)
blogs$Date <- ymd_hms(blogs$Date)
View(blogs)
# Remove all NAs
blogs <- blogs[rowSums(is.na(blogs)) == 0,]
View(blogs)
#### Load in data ####
setwd('~/Gitdir/PIPPY-data/Data/Blogs')
blogs <- data.frame()
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)) {assign('blog_name', read.csv(temp[i], na.strings = ""))
if(!is.null(blog_name$Date)){
blog_name <- blog_name[c('Date','Text')]
blogs<- rbind(blogs,blog_name)}
}
#### Clean the data ####
# Remove all NAs
blogs <- blogs[rowSums(is.na(blogs)) == 0,]
# Change text to character
blogs$Text <- as.character(blogs$Text)
# Change date to dates
blogs$Date <- as.character(blogs$Date)
blogs$Date <- gsub("\\['|\\']", "", blogs$Date)
blogs$Date <- ymd_hms(blogs$Date)
str(blogs)
pMiss <- function(x){sum(is.na(x))/length(x)*100}
blogs$Date[blogs$Date==""] <- NA
blogs$Date[blogs$Date=='None']<-NA
blogs$Text[blogs$Text==""] <- NA
keepers <- which(apply(blogs,1,pMiss)==0)
gBlogs <- blogs[keepers,]
gblogs <- blogs
gBlogs <- blogs
gBlogs$Text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", gBlogs$Text)
# remove at people
gBlogs$Text = gsub("@\\w+", "", gBlogs$Text)
# remove punctuation
gBlogs$Text = gsub("[[:punct:]]", "", gBlogs$Text)
# remove numbers
gBlogs$Text = gsub("[[:digit:]]", "", gBlogs$Text)
# remove html links
gBlogs$Text = gsub("http\\w+", "", gBlogs$Text)
# remove unnecessary spaces
gBlogs$Text = gsub("[ \t]{2,}", "", gBlogs$Text)
gBlogs$Text = gsub("^\\s+|\\s+$", "", gBlogs$Text)
gBlogs$Text = gsub('???','',gBlogs$Text)
gBlogs$Text = gsub('etc','',gBlogs$Text)
# define "tolower error handling" function
try.error = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# lower case using try.error with sapply
gBlogs$Text = sapply(gBlogs$Text, try.error)
# remove NAs in gBlogs$Text
gBlogs$Text = gBlogs$Text[!is.na(gBlogs$Text)]
names(gBlogs$Text) = NULL
View(gBlogs)
